{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"notebook_connected\"\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics \n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import seaborn as sns\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Functions <h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression with RFE\n",
    "def RFE_logistic(dataframe, y, n_features):\n",
    "    logreg = LogisticRegression()\n",
    "    y = y.astype(int)\n",
    "    \n",
    "    rfe = RFE(logreg, n_features_to_select=n_features)\n",
    "    rfe = rfe.fit(dataframe, y)\n",
    "    print(rfe.support_)\n",
    "    print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_logistic (dataframe, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(dataframe, y, test_size = 0.3)\n",
    "    y_train = y_train.astype(int)\n",
    "\n",
    "    logreg = LogisticRegression()\n",
    "    logreg.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = logreg.predict(X_test)\n",
    "    print('Accuracy on test set: {:.2f}'.format (logreg.score(X_test, y_test)))\n",
    "    plot_confusion_matrix(logreg, X_test, y_test)\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_comparison(data, k):\n",
    "    x = data[['radius_mean','texture_mean']].values\n",
    "    y = data['prediction'].astype(int).values\n",
    "    clf = neighbors.KNeighborsClassifier(n_neighbors=k)\n",
    "    clf.fit(x, y)\n",
    "    #Plotting decision region\n",
    "    plot_decision_regions(x, y, clf=clf, legend=2)\n",
    "    #Adding axes annotations\n",
    "    plt.xlabel('radius_mean')\n",
    "    plt.ylabel('texture_mean')\n",
    "    plt.title('Knn with K='+ str(k))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Loading dataset and EDA <h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " df = pd.read_csv(\"/Users/dominik/Desktop/breast-cancer.csv\")  \n",
    " df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**we can see that whe have enough \"malignant\" labels, so we don't have to worry about not sufficient amount of the true labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['diagnosis'] == 'M', 'diagnosis'] = 1\n",
    "df.loc[df['diagnosis'] == 'B', 'diagnosis'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns[1:]:\n",
    "    \n",
    "    fig = px.histogram(df[col], nbins = 60)\n",
    "    fig.update_layout(bargap=0)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = df.corr()\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Heatmap(\n",
    "    z=np.array(df_corr),\n",
    "    x=df_corr.index ,\n",
    "    y=df_corr.columns,\n",
    "    colorscale=px.colors.diverging.RdBu,\n",
    "    zmin=-1,\n",
    "    zmax=1\n",
    "    )\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('diagnosis').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This gives us a really clear view on which variables can matter while building a classification algorithm. For example, area_mean or concavity_mean seem to be really important, whereas fractal_dimension_mean or symmetry_mean have similar values for both labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = df.iloc[:, 1:]\n",
    "\n",
    "\n",
    "for col in df.columns[1:]:\n",
    "\n",
    "    fig = px.histogram(\n",
    "    df,\n",
    "    x = \"diagnosis\",\n",
    "    y = col,\n",
    "    color = \"diagnosis\",\n",
    "    histfunc = \"avg\"\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I've decided to create a classification model based on parameters describing mean values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = [df[col] for col in df.columns if 'mean' in col]\n",
    "df_model = pd.DataFrame(df_model).T\n",
    "y = df['diagnosis']\n",
    "df_model.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Configurating classification algorithms <h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> I will try to fit 3 logistic regression models: <h2>\n",
    "<h3>\n",
    "1. Model with all variables from df_model dataframe <br>\n",
    "2. 2 RFE models, which builds multiple models and checks if adding an additional variables makes the model better (will select 6 and 8 features) \n",
    "<h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smlog = sm.Logit(y, sm.add_constant(df_model))\n",
    "results = smlog.fit()\n",
    "print(results.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability = 1 / (1 + np.exp(-results.fittedvalues))\n",
    "px.histogram(probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_logistic(df_model, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Second model (RFE with 8 features)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model2 = df_model.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFE_logistic(df_model2, y, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model2 = df_model2.drop(['area_mean', 'fractal_dimension_mean'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smlog = sm.Logit(y, sm.add_constant(df_model2))\n",
    "results = smlog.fit()\n",
    "print(results.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability = 1 / (1 + np.exp(-results.fittedvalues))\n",
    "px.histogram(probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_logistic(df_model2, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Third model: RFE Logistic with 5 features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model3 = df_model.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFE_logistic(df_model3, y, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model3 = df_model3.drop(['texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean', 'fractal_dimension_mean'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smlog_3 = sm.Logit(y, sm.add_constant(df_model3))\n",
    "results = smlog_3.fit()\n",
    "print(results.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability = 1 / (1 + np.exp(-results.fittedvalues))\n",
    "px.histogram(probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_logistic(df_model3, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Using SVM <h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_model, y, test_size = 0.3, random_state = 0)\n",
    "X_train_scaled = scale(X_train)\n",
    "X_test_scaled = scale(X_test)\n",
    "\n",
    "svm = SVC()\n",
    "svm.fit(X_train_scaled, y_train)\n",
    "y_pred = svm.predict(X_test_scaled)\n",
    "plot_confusion_matrix(svm, X_test_scaled, y_test)\n",
    "print(\"Accuracy on test set: {}\".format(svm.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As we can see, SVM perform better. It is more often chosen when it comes to handling little datasets. Let's find out if we can somehow optimize the parameters by executing Cross Validation (GridSearchCV)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_gamma = ['scale']\n",
    "additional_gammas = np.arange(0, 1, 0.01)\n",
    "additional_gammas = additional_gammas.tolist()\n",
    "gammas = initial_gamma + additional_gammas\n",
    "\n",
    "param_grid = [\n",
    "    {'C': np.arange(1, 100, 1),\n",
    "    'gamma': gammas,\n",
    "    'kernel': ['rbf']}\n",
    "]\n",
    "\n",
    "optimal_params = GridSearchCV(\n",
    "    SVC(),\n",
    "    param_grid,\n",
    "    cv = 5,\n",
    "    scoring = 'accuracy',\n",
    "    verbose = 2\n",
    ")\n",
    "\n",
    "optimal_params.fit(X_train_scaled, y_train)\n",
    "print(optimal_params.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It seems like C = 81, gamma = 0.02 are the optimal values of parameters, let's fit a final SVM model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_svm = SVC(C = 81, gamma = 0.02)\n",
    "reg_svm.fit(X_train_scaled, y_train)\n",
    "plot_confusion_matrix(reg_svm, X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reg_svm.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We were able to achieve better performance of the model with a regularization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now let's try other classification algorithms (KNN, Decision Tree Classification, Random Forest)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for neighbor in n_neighbors:\n",
    "     knn = KNeighborsClassifier(n_neighbors = neighbor)\n",
    "     knn.fit(X_train_scaled, y_train)\n",
    "     y_pred = knn.predict(X_test_scaled)\n",
    "     print('For the number of neighbors {:.2f}'.format(neighbor) + ' accuracy = {:.2f}'.format(knn.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The smallest number of neighbors giving the best predictions is 6, let's take a closer look at this configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 6)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "y_pred = knn.predict(X_test_scaled)\n",
    "\n",
    "plot_confusion_matrix(knn, X_test_scaled, y_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Once again we've found a better performance than logistic regression, however, a little bit worse than SVM. Let's try to visualize the Test Set results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_visualize = X_test_scaled.copy()\n",
    "df_visualize = pd.DataFrame(df_visualize)\n",
    "df_visualize.columns = X_test.columns\n",
    "df_visualize ['prediction'] = y_pred\n",
    "sns.relplot(x = 'radius_mean', y = 'texture_mean', hue = 'prediction', data = df_visualize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As we can see - larger mean of the tumor radius and texture leads to the positive prediction of the cancer \n",
    "Let's find out how the decision surface looks like for these two characteristics for differenct configurations of the number of neighbors.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [1, 5, 6, 20, 30, 40, 80]:\n",
    "    knn_comparison(df_visualize, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f640a9078f8e092032cb0185e0c2b2c1ad2376cf3b94da3c4476fa7bf4b3609c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
