{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"notebook_connected\"\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics \n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import seaborn as sns\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Functions <h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression with RFE\n",
    "def RFE_logistic(dataframe, y, n_features):\n",
    "    logreg = LogisticRegression()\n",
    "    y = y.astype(int)\n",
    "    \n",
    "    rfe = RFE(logreg, n_features_to_select=n_features)\n",
    "    rfe = rfe.fit(dataframe, y)\n",
    "    print(rfe.support_)\n",
    "    print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_logistic (dataframe, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(dataframe, y, test_size = 0.3)\n",
    "    y_train = y_train.astype(int)\n",
    "\n",
    "    logreg = LogisticRegression()\n",
    "    logreg.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = logreg.predict(X_test)\n",
    "    print('Accuracy on test set: {:.2f}'.format (logreg.score(X_test, y_test)))\n",
    "    plot_confusion_matrix(logreg, X_test, y_test)\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_comparison(data, k):\n",
    "    x = data[['radius_mean','texture_mean']].values\n",
    "    y = data['prediction'].astype(int).values\n",
    "    clf = neighbors.KNeighborsClassifier(n_neighbors=k)\n",
    "    clf.fit(x, y)\n",
    "    #Plotting decision region\n",
    "    plot_decision_regions(x, y, clf=clf, legend=2)\n",
    "    #Adding axes annotations\n",
    "    plt.xlabel('radius_mean')\n",
    "    plt.ylabel('texture_mean')\n",
    "    plt.title('Knn with K='+ str(k))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Loading dataset and EDA <h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " df = pd.read_csv(\"/Users/dominik/Desktop/breast-cancer.csv\")  \n",
    " df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**we can see that whe have enough \"malignant\" labels, so we don't have to worry about not sufficient amount of the true labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['diagnosis'] == 'M', 'diagnosis'] = 1\n",
    "df.loc[df['diagnosis'] == 'B', 'diagnosis'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns[1:]:\n",
    "    \n",
    "    fig = px.histogram(df[col], nbins = 60)\n",
    "    fig.update_layout(bargap=0)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = df.corr()\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Heatmap(\n",
    "    z=np.array(df_corr),\n",
    "    x=df_corr.index ,\n",
    "    y=df_corr.columns,\n",
    "    colorscale=px.colors.diverging.RdBu,\n",
    "    zmin=-1,\n",
    "    zmax=1\n",
    "    )\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('diagnosis').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This gives us a really clear view on which variables can matter while building a classification algorithm. For example, area_mean or concavity_mean seem to be really important, whereas fractal_dimension_mean or symmetry_mean have similar values for both labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = df.iloc[:, 1:]\n",
    "\n",
    "\n",
    "for col in df.columns[1:]:\n",
    "\n",
    "    fig = px.histogram(\n",
    "    df,\n",
    "    x = \"diagnosis\",\n",
    "    y = col,\n",
    "    color = \"diagnosis\",\n",
    "    histfunc = \"avg\"\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I've decided to create a classification model based on parameters describing mean values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = [df[col] for col in df.columns if 'mean' in col]\n",
    "df_model = pd.DataFrame(df_model).T\n",
    "y = df['diagnosis']\n",
    "df_model.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Configurating classification algorithms <h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> I will try to fit 3 logistic regression models: <h2>\n",
    "<h3>\n",
    "1. Model with all variables from df_model dataframe <br>\n",
    "2. 2 RFE models, which builds multiple models and checks if adding an additional variables makes the model better (will select 6 and 8 features) \n",
    "<h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smlog = sm.Logit(y, sm.add_constant(df_model))\n",
    "results = smlog.fit()\n",
    "print(results.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability = 1 / (1 + np.exp(-results.fittedvalues))\n",
    "px.histogram(probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_logistic(df_model, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Second model (RFE with 8 features)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model2 = df_model.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFE_logistic(df_model2, y, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model2 = df_model2.drop(['area_mean', 'fractal_dimension_mean'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smlog = sm.Logit(y, sm.add_constant(df_model2))\n",
    "results = smlog.fit()\n",
    "print(results.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability = 1 / (1 + np.exp(-results.fittedvalues))\n",
    "px.histogram(probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_logistic(df_model2, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Third model: RFE Logistic with 5 features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model3 = df_model.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFE_logistic(df_model3, y, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model3 = df_model3.drop(['texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean', 'fractal_dimension_mean'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smlog_3 = sm.Logit(y, sm.add_constant(df_model3))\n",
    "results = smlog_3.fit()\n",
    "print(results.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability = 1 / (1 + np.exp(-results.fittedvalues))\n",
    "px.histogram(probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_logistic(df_model3, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Using SVM <h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_model, y, test_size = 0.3, random_state = 0)\n",
    "X_train_scaled = scale(X_train)\n",
    "X_test_scaled = scale(X_test)\n",
    "\n",
    "svm = SVC()\n",
    "svm.fit(X_train_scaled, y_train)\n",
    "y_pred = svm.predict(X_test_scaled)\n",
    "plot_confusion_matrix(svm, X_test_scaled, y_test)\n",
    "print(\"Accuracy on test set: {}\".format(svm.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As we can see, SVM perform better. It is more often chosen when it comes to handling little datasets. Let's find out if we can somehow optimize the parameters by executing Cross Validation (GridSearchCV)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_gamma = ['scale']\n",
    "additional_gammas = np.arange(0, 1, 0.01)\n",
    "additional_gammas = additional_gammas.tolist()\n",
    "gammas = initial_gamma + additional_gammas\n",
    "\n",
    "param_grid = [\n",
    "    {'C': np.arange(1, 100, 1),\n",
    "    'gamma': gammas,\n",
    "    'kernel': ['rbf']}\n",
    "]\n",
    "\n",
    "optimal_params = GridSearchCV(\n",
    "    SVC(),\n",
    "    param_grid,\n",
    "    cv = 5,\n",
    "    scoring = 'accuracy',\n",
    "    verbose = 2\n",
    ")\n",
    "\n",
    "optimal_params.fit(X_train_scaled, y_train)\n",
    "print(optimal_params.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It seems like C = 81, gamma = 0.02 are the optimal values of parameters, let's fit a final SVM model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_svm = SVC(C = 81, gamma = 0.02)\n",
    "reg_svm.fit(X_train_scaled, y_train)\n",
    "plot_confusion_matrix(reg_svm, X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reg_svm.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We were able to achieve better performance of the model with a regularization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now let's try other classification algorithms (KNN, Decision Tree Classification, Random Forest)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> KNN <h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for neighbor in n_neighbors:\n",
    "     knn = KNeighborsClassifier(n_neighbors = neighbor)\n",
    "     knn.fit(X_train_scaled, y_train)\n",
    "     y_pred = knn.predict(X_test_scaled)\n",
    "     print('For the number of neighbors {:.2f}'.format(neighbor) + ' accuracy = {:.2f}'.format(knn.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The smallest number of neighbors giving the best predictions is 6, let's take a closer look at this configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 6)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "y_pred = knn.predict(X_test_scaled)\n",
    "\n",
    "plot_confusion_matrix(knn, X_test_scaled, y_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Once again we've found a better performance than logistic regression, however, a little bit worse than SVM. Let's try to visualize the Test Set results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_visualize = X_test_scaled.copy()\n",
    "df_visualize = pd.DataFrame(df_visualize)\n",
    "df_visualize.columns = X_test.columns\n",
    "df_visualize ['prediction'] = y_pred\n",
    "sns.relplot(x = 'radius_mean', y = 'texture_mean', hue = 'prediction', data = df_visualize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As we can see - larger mean of the tumor radius and texture leads to the positive prediction of the cancer \n",
    "Let's find out how the decision surface looks like for these two characteristics for differenct configurations of the number of neighbors.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [1, 5, 6, 20, 30, 40, 80]:\n",
    "    knn_comparison(df_visualize, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's try to fit the first decision tree to our training data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Decision tree <h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_dt = DecisionTreeClassifier()\n",
    "clf_dt = clf_dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's see how our first tree looks like**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (150,120))\n",
    "_ = tree.plot_tree(clf_dt, feature_names = X_train.columns, class_names = [\"No cancer\", \"Cancer\"], filled = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(clf_dt, X_test, y_test)\n",
    "y_pred = clf_dt.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can clearly see that our classification tree overfits the data. Moreover, the tree is really huge and maybe we can make it smaller. Let's try to execute data pruning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = clf_dt.cost_complexity_pruning_path(X_train, y_train)\n",
    "ccp_alphas = path.ccp_alphas\n",
    "ccp_alphas = ccp_alphas[:-1]\n",
    "\n",
    "clf_dts = []\n",
    "\n",
    "for ccp_alpha in ccp_alphas:\n",
    "    clf_dt = DecisionTreeClassifier(ccp_alpha = ccp_alpha)\n",
    "    clf_dt.fit(X_train, y_train)\n",
    "    clf_dts.append(clf_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores = [clf_dt.score(X_train, y_train) for clf_dt in clf_dts]\n",
    "test_scores = [clf_dt.score(X_test, y_test) for clf_dt in clf_dts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel('alpha')\n",
    "ax.set_ylabel('accuracy')\n",
    "ax.set_title('Accuracy depending on the alpha parameter: training vs. testing')\n",
    "ax.plot(ccp_alphas, train_scores, marker = 'o', label = 'train', drawstyle = 'steps-post')\n",
    "ax.plot(ccp_alphas, test_scores, marker = 'o', label = 'test', drawstyle = 'steps-post')\n",
    "ax.legend()\n",
    "plt.show\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can see that our optimal value of alpha is somewhere between 0 and 0.005**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**we may assume that our \"best\" tree performed this good only on one specific type of the training data, a good idea is to perform cross validation with every value of alpha and check which configuration has the largest mean of the accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics = []\n",
    "best_score = 0\n",
    "best_alpha = 0\n",
    "for ccp_alpha in ccp_alphas:\n",
    "    clf_dt = DecisionTreeClassifier(ccp_alpha = ccp_alpha)\n",
    "    clf_dt.fit(X_train, y_train)\n",
    "    scores = cross_val_score(clf_dt, X_train, y_train, cv = 10)\n",
    "    statistics.append([ccp_alpha, np.mean(scores), np.std(scores)])\n",
    "    if np.mean(scores) > best_score:\n",
    "        best_score = np.mean(scores)\n",
    "        best_alpha = ccp_alpha\n",
    "\n",
    "print(\"best alpha value: {}\".format(best_alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = pd.DataFrame(statistics, columns = ['alpha_value', 'mean_accuracy', 'standard_deviation'])\n",
    "cv_results.plot(x = 'alpha_value', y = 'mean_accuracy', yerr = 'standard_deviation', marker = 'o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's see our final model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_dt = DecisionTreeClassifier(ccp_alpha = 0.00326737)\n",
    "clf_dt.fit(X_train, y_train)\n",
    "plot_confusion_matrix(clf_dt, X_test, y_test)\n",
    "\n",
    "y_pred = clf_dt.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**And the final tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (100,80))\n",
    "_ = tree.plot_tree(clf_dt, feature_names = X_train.columns, class_names = [\"No cancer\", \"Cancer\"], filled = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**By performing cross validation and tree pruning we were able to achieve higher accuracy and construct a simpler tree.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Random Forest <h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's see what is the optimal value for the number of trees**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the number of trees: 20, traininig accuracy = 0.9985940246045695, testing accuracy= 0.9344463971880492\n",
      "For the number of trees: 40, traininig accuracy = 0.9989455184534272, testing accuracy= 0.9400702987697717\n",
      "For the number of trees: 60, traininig accuracy = 1.0, testing accuracy= 0.9416520210896309\n",
      "For the number of trees: 80, traininig accuracy = 1.0, testing accuracy= 0.9418277680140597\n",
      "For the number of trees: 100, traininig accuracy = 1.0, testing accuracy= 0.9427065026362037\n",
      "For the number of trees: 120, traininig accuracy = 1.0, testing accuracy= 0.9420035149384883\n",
      "For the number of trees: 140, traininig accuracy = 1.0, testing accuracy= 0.9404217926186291\n"
     ]
    }
   ],
   "source": [
    "num_trees = [20, 40, 60, 80, 100, 120, 140]\n",
    "configurations = []\n",
    "for trees in num_trees:\n",
    "    performance_train = []\n",
    "    performance_test = []\n",
    "    \n",
    "    for i in range(10):\n",
    "        model = RandomForestClassifier(n_estimators = trees, oob_score=True)\n",
    "        model.fit(df_model, y)\n",
    "    \n",
    "        score_train = model.score(df_model, y)\n",
    "        score_test = model.oob_score_\n",
    "        performance_train.append(score_train)\n",
    "        performance_test.append(score_test)\n",
    "\n",
    "    configurations.append([trees, np.mean(performance_train), np.mean(performance_test)])\n",
    "    print(\"For the number of trees: {}, traininig accuracy = {}, testing accuracy= {}\".format(trees, np.mean(performance_train), np.mean(performance_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It seems like the number of trees = 100 is an optimal value. Let's fit a final model and check the importance of the features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = df_model.columns\n",
    "\n",
    "forest = RandomForestClassifier()\n",
    "forest.fit(df_model, y)\n",
    "\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAEYCAYAAAAaryJBAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAA3LklEQVR4nO3dd5hkRbnH8e9vVzIs4CXHBUQUCYqLgOBlRbmCKChJCSoIYoArJlSQCwgKgiIqGEhySSoShEUJIghXBclLVCRLFIm7Lu6SfvePqrPbM9sz07tMnzoz/X6eZ56ZPt3T552e6q5z6rz1lmwTQggh1G1M6QBCCCH0puiAQgghFBEdUAghhCKiAwohhFBEdEAhhBCKiA4ohBBCEdEBhVFL0gGSTiodRy+J1zzMCcU8oNCOpAeApYGXWza/3vajr/I597T9u1cX3cgj6RDgdbZ3LR3LSCXJwD+B5Wy/lLfNAzwCLGlbeduVwIbAi4CBu4GzgWNsz8iPOYT4fxQXZ0BhMO+3vXDL11x3PsNB0mtK7n9ujdS4G+oZYMuW21vmbf3tY3sRYFngi8CHgYskqfshhk5FBxTmiKRFJZ0s6TFJj0j6hqSx+b7VJF0h6SlJT0o6U9Ji+b7TgZWACyX9S9KXJU2U9HC/539A0rvzz4dIOkfSGZKmALsNtv82sR4i6Yz883hJlrS7pIckPSPpU5LWl3SrpGclHdfyu7tJ+pOk4yQ9J+mvkt7Vcv9ykiZJelrSPZI+0W+/rXF/CjgA+FD+22/Jj9td0l8kTZV0n6RPtjzHREkPS/qipCfy37t7y/0LSDpa0oM5vj9KWiDft6Gkq/PfdIukif3+rvvyPu+XtMsAr93/SvpG/3habn8lv/5TJd1VvTYDvOYfk/T33Ca+1u9vODX/L/6S20Sf9tDG6cBHW25/FDhtoAfbnmb7SmBrYCNgqyGeP9QoOqAwp/4XeAl4HfAW4L+APfN9Ao4AlgPeCKwIHAJg+yPA35l1VnVUh/vbBjgHWAw4c4j9d2IDYHXgQ8D3gK8B7wbeBOwoadN+j70XWAI4GDhP0mvzfb8AHs5/6/bA4ZI2GyDuk4HDgbPy375ufswTwPuAccDuwDGS1mt5jmWARYHlgT2AH0paPN/3HeCtwNuB1wJfBl6RtDzwG+AbefuXgHMlLSlpIeAHwJb57ODtwOQ5eO0AkLQGsA+wfn6e9wAPDPIrmwBrAO8CDpL0xrz9YGA8sCqwOdDJcNj5wH9KWiy/Fu8ALhjql2z/HbghPz40RHRAYTDn56PoZyWdL2lp4L3A5/KR5RPAMaThDWzfY/sy2zNs/xP4LrDpwE/fkWtsn2/7FdIH9YD779Bhtqfb/i0wDfi57SdsPwL8gdSpVZ4Avmf7RdtnAXcBW0laEdgY+Ep+rsnASfQ9Mp8Zt+1/twvE9m9s3+vkKuC39P2AfBE4NO//IuBfwBqSxgAfB/a1/Yjtl21fna9v7ApcZPuivO/LSB+8783P+QqwlqQFbD9m+445eO0qLwPzAWtKmsf2A7bvHeTxX7f9b9u3ALcAVQe8I3C47WdsP0zqHIcyHbiQdADxIWBS3taJR0mdcmiI6IDCYD5ge7H89QFgZWAe4LGqYwKOB5YCkLS0pF/koZkpwBmks4dX46GWnwfdf4f+0fLzv9vcXrjl9iPum6XzIOmMZzngadtT+923/ABxtyVpS0l/zsN4z5I6idbX66nqYnv2fI5vCWB+0tlZfysDO7QcODxLOgNZ1vY00of2p0iv4W8kvWGoOPuzfQ/wOdLZ7RP5f77cIL/yeJu/AdLr2Po6DfmaZaeROvtBh9/aWB54eg4eH7osOqAwJx4CZgBLtHRM42y/Kd9/OCnraG3b40hH460XffunXE4DFqxu5Gs5S/Z7TOvvDLX/4ba81Oei9Uqko+hHgddKWqTffY8MEPdstyXNB5xLGkpb2vZiwEX0fb0G8iTpqH+1Nvc9BJze8vosZnsh298CsH2p7c1JF+f/Cpw4wD76/G9Iw4Gz/hj7Z7Y3IXV4Bo7sIO7+HgNWaLm9Yoe/9wdS/EsDf+zkF/JZ61vz74aGiA4odMz2Y6RhoqMljZM0RinxoBpmW4Q0TPRcvhaxX7+n+AdpvL/yN2B+SVsppdMeSBramdv9D7elgM9KmkfSDqTrWhfZfgi4GjhC0vyS1iFdozljkOf6BzA+D58BzEv6W/8JvCRpS9L1rCHl4cifAt9VSoYYK2mj3KmdAbxf0nvy9vlzAsEK+Qx1m3wtaAbpf/XKALuZDLxX0mslLUM64wHSNSBJm+X9TSedOQ70PIP5JbC/pMVze9mnw7/fwPuBrfudoc5G0oK5fVwAXEfq5ENDRAcU5tRHSR+ed5LSX88hHY0CfB1YD3iOdCH8vH6/ewRwYB4a+pLt54DPkK6fPEI66h4qC2qw/Q+3a0kJC08C3wS2t/1Uvm8n0gX0R4FfAQcPMb/p7Pz9KUk35eG7z5I+hJ8BdiZdz+jUl4DbgOtJw0pHAmNy57gNKevun6Qzov1I7/UxwBdyzE+Trs99eoDnP510veYBUqd/Vst98wHfIr0uj5M66v3nIPbKoaT/9/3A70j/yxmd/KLtO4a4fnWcpKmkjv97pLPNLXLnHRoiJqKG0Iak3UiTZjcpHUuvkPRp4MO2u3VGGxpmyDMgSTdK2rsl/TOEEF41SctK2jgPpa5BmjD6q9Jxhfp0MgT3IVK2yvU52+U9/S7MhhDC3JiXlMU4FbiCdJ3mR0UjCrXqeAguXzx9H/Bj0jyAU4Dv2460xhBCCHOsoySEnOVzNPBt0sW8HYAppKOWEEIIYY4NWSRR0o3As6RyIl+tqskC10rauIuxtbXEEkt4/Pjxde82hBDCXLjxxhuftN1/fh/QQQcE7GD7vtYNklaxfb/tbYclwjkwfvx4brjhhrp3G0IIYS5IenCg+zoZgjunw20hhBBCxwY8A8o1ot4ELCqp9UxnHKkOVQghhDDXBhuCW4OU9bYYqexFZSrwiXa/EEIIIXRqwA7I9gXABZI2sn1NjTGFEELoAYMNwX05Lxq2s6Sd+t9v+7NdjSyEELpg4sSJAFx55ZVF4wiDD8H9JX+PlLMQQgjDbrAhuAvz+ixr2/5SjTGFEELoAYOmYdt+mbT0cAghhDCsOpmIOlnSJNJ6JtOqjbb7r/USQgghdKyTDmh+4Clgs5ZtZvbFxkIIIYSODdkB2d69jkBCCCH0lk6KkZ5COuPpw/bHuxJRCCGEntDJENyvW36eH/ggaU35EEIIYa51MgR3buttST8H/ti1iEIIIfSEjhak62d1YKnhDiSEEEJv6eQa0FTSNSDl748DX+lyXCGEEEa5TobgFqkjkBBCCL2lkyQE8npAm5DOgP5g+/xuBhVCCGH0G/IakKQfAZ8CbgNuBz4l6YfdDiyEEMLo1skZ0GbAG20bQNKpwB1djSqEEMKo10kW3D3ASi23V8zbQgghhLnWyRnQIsBfJF2Xb68P3JALlGJ7624FF0IIYfTqpAM6qOtRhBBC6DmdpGFfBSBpXOvjbT/dxbhCCCGMcp1kwe0l6XHgVtLy3DfS4TLdkraQdJekeyR9dZDHbSfJkiZ0GngIIYSRrZMhuP2AtWw/OSdPnJfz/iGwOfAwcL2kSbbv7Pe4RYB9gWvn5PlDCCGMbJ1kwd0LPD8Xz/024B7b99l+AfgFsE2bxx0GHAlMn4t9hC6ZOHEiEydOLB1GCGEU6+QMaH/gaknXAjOqjbY/O8TvLQ881HL7YWCD1gdIWg9Y0fZvJO030BNJ2gvYC2CllVYa6GFhlKs6xCuvvLJoHCGE4dFJB3Q8cAWpEsIrw7VjSWOA7wK7DfVY2ycAJwBMmDBhtsXxQgghjDyddEDz2P7CXDz3I6RJq5UV8rbKIsBawJWSAJYBJkna2nZHSQ4hhBBGrk6uAV2cM+GWlfTa6quD37seWF3SKpLmBT4MTKrutP2c7SVsj7c9HvgzEJ1PCCH0iE7OgHbK3/dv2WZg1cF+yfZLkvYBLgXGAj+1fYekQ4EbbE8a7PdDCCGMbp1MRF1lbp/c9kXARf22ta2sYHvi3O4nhBDCyDNgByRpM9tX5LWAZmP7vO6FFUIIYbQb7AxoU1L22/vb3GcgOqAQQghzbcAOyPbB+fvu9YUTQgihV3SSBRdCCCEMu+iAQgghFBEdUAghhCI6mQeEpLcD4+m7HtBpXYophDBKRP2+MJghOyBJpwOrAZOBl/NmA9EBhRBCmGudnAFNANa0HUVAQwghDJtOrgHdTioUGkIIIQybTs6AlgDulHQdfdcD2rprUYUQQhj1OumADul2EHWLC6MhhFBeJ8VIr6ojkBBCCL1lsGKkf7S9iaSppKy3mXcBtj2u69GFEEIYtQarBbdJ/r5IfeGEEELoFVEJIYQQQhHRAYUQQigiOqAQQghFdNQBSVpZ0rvzzwtIiutCIYQQXpUhOyBJnwDOAY7Pm1YAzu9iTCGEEHpAJ2dAewMbA1MAbN8NLNXNoEIIIYx+nVRCmGH7BUkASHoNfecFhRBCY4z/6m8Gvf/x+57q6HEPfGurYYsptNfJGdBVkg4AFpC0OXA2cGF3wwohhDDaddIBfRX4J3Ab8EngIuDAbgYVQghh9OukFtwrwInAiZJeC6wQawOFEEJ4tTrJgrtS0rjc+dxI6oiO6X5oIYQQRrNOhuAWtT0F2BY4zfYGwLu6G1YIIYTRrpMO6DWSlgV2BH49J08uaQtJd0m6R9JX29z/BUl3SrpV0uWSVp6T5w8hhDByddIBHQpcCtxj+3pJqwJ3D/VLksYCPwS2BNYEdpK0Zr+H3QxMsL0OabLrUXMSfAghhJFryA7I9tm217H9mXz7PtvbdfDcbyN1WvfZfgH4BbBNv+f+ve3n880/k6oshBBC6AFDZsFJmh/YA3gTMH+13fbHh/jV5YGHWm4/DGwwyOP3AC4eIIa9gL0AVlpppaFCDiGEMAJ0MgR3OrAM8B7gKtJZytThDELSrsAE4Nvt7rd9gu0JticsueSSw7nrEEIIhXTSAb3O9v8A02yfCmzF4GcylUeAFVtur5C39ZGrbH8N2Nr2jA6eN4QQwijQSQf0Yv7+rKS1gEXprBjp9cDqklaRNC/wYWBS6wMkvYVUZXtr2090HnYIIYSRrpNipCdIWhz4H1IHsjBw0FC/ZPslSfuQMujGAj+1fYekQ4EbbE8iDbktDJydi53+3fbWc/enhBBCGEk6KcVzUv7xKmDVOXly2xeRase1bjuo5ed3z8nzhdEtqhiH0Fs6KcWztKSTJV2cb68paY/uhxZCCGE062QI7n+BU0iJAgB/A84CTu5STKEGcbYRQiitkySEJWz/EngF0rUd4OWuRhVCCGHU66QDmibpP8iroEraEHiuq1GFEObKxIkTmThxYukwQuhIJ0NwXyBlv60m6U/AksD2XY0qhBDCqDdoB5QLim6av9YABNxl+8XBfi+EEEIYyqAdkO2XJe1k+xjgjppiCiGMEMOVzAKR0NKLOhmC+5Ok40iZb9OqjbZv6lpUIYQQRr1OOqA35++HtmwzsNmwRxNCCKFndFIJ4Z11BBJCCKG3dLIe0OHAUbafzbcXB75o+8AuxzbXRuIkyyp19sorr6xtnyGEUFIn84C2rDofANvPAO/tWkQhhBB6Qicd0FhJ81U3JC0AzDfI40MIIYQhdZKEcCZwuaRT8u3dgVO7F1IIIYRe0EkSwpGSbgGqpRMOs31pd8MKIYQw2nVyBgTwF+Al27+TtKCkRWxP7WZgIYQQRrdO1gP6BHAOaelsgOWB87sYUwghhB7QSRLC3sDGwBQA23cDS3UzqBBCCKNfJ0NwM2y/IAkASa8hL80QOjcS5yaFEEI3dXIGdJWkA4AFJG0OnA1c2N2wQgghjHadnAF9FdgDuA34JHARcFI3gwphJChRvSLOpMNo0kka9ivAifkrhBBCGBYDdkCSbmOQaz221+lKRCGE0EN6uQ7kYGdA78vf987fT8/fdyWSEEIIIbxKA3ZAth8EkLS57be03PUVSTeRrg2FEEIIc6WTJARJ2tj2n/KNt9NZ9lwII1osNx16VV3Dgp10QHsAP5W0aL79LPDxTp5c0hbA94GxwEm2v9Xv/vmA04C3Ak8BH7L9QEeRjzLL7PytoR8UQhhx4kBmYJ1kwd0IrFt1QLaf6+SJJY0FfghsDjwMXC9pku07Wx62B/CM7ddJ+jBwJPChOfwbQgghzIGmpPN3PJRm+7lOO5/sbcA9tu+z/QLwC2Cbfo/ZhllLO5wDvEtVyYUQQgijmuzuJLRJ2h7Ywvae+fZHgA1s79PymNvzYx7Ot+/Nj3my33PtBewFsNJKK731wQcffFWx9XLaY6ea+Bo1Maamadpr1LR4oJkxjWaSbrQ9od19IyKZwPYJtifYnrDkkkuWDieEEMIw6Gg9oJz5Nr718bZPG+LXHgFWbLm9Qt7W7jEP5yKni5KSEUIIIYxyQ3ZAkk4HVgMmAy/nzSZlrw3memB1SauQOpoPAzv3e8wk4GPANcD2wBXu1phgCCGERunkDGgCsOacdgy2X5K0D3ApKQ37p7bvkHQocIPtScDJwOmS7gGeJnVSIYQQekAnHdDtwDLAY3P65LYvIlXPbt12UMvP04Ed5vR5QwghjHyddEBLAHdKug6YUW20vXXXogohhC6J7Lfm6KQDOqTbQYQQQug9nVRCuKqOQEIIr14c3YeRZMh5QJI2lHS9pH9JekHSy5Km1BFcCCGE0auTiajHATsBdwMLAHuSaryFEEIIc62jSgi27wHG2n7Z9inAFt0NK4QQwmjXSRLC85LmBSZLOoqUjj0iSviE0SWub4QwunTSAX2E1OHsA3yeVDpnu24GFUIYHeKgIQymkyy4ByUtACxr++s1xBRCCKEHdFIL7v3Ad4B5gVUkvRk4dCRPRI2jshBCKK/TiahvA64EsD05FxgNo1h00iGEbuskmeDFNiuhRsXqEEIIr0onZ0B3SNoZGCtpdeCzwNXdDSuEEMJo18kZ0H8DbyIVIv05MAX4XBdjCiGE0AM6yYJ7Hvha/gohhBCGhQZaZ07SpMF+sVQWnKR/Ag8Ow1MtATw5DM8znJoWU9PigebF1LR4oHkxNS0eaF5MTYsHhi+mlW0v2e6Owc6ANgIeIg27XQtoGAJ51Qb6Q+aUpBtsTxiO5xouTYupafFA82JqWjzQvJiaFg80L6amxQP1xDRYB7QMsDmpEOnOwG+An9u+o5sBhRBC6A0DJiHkwqOX2P4YsCFwD3ClpH1qiy6EEMKoNWgSgqT5gK1IZ0HjgR8Av+p+WLU4oXQAbTQtpqbFA82LqWnxQPNialo80LyYmhYP1BDTYEkIpwFrARcBv7B9e7eDCSGE0DsG64BeAablm60PEmDb47ocWwghhFFswA4ohBBC6KZYWC6EEEIR0QGFEEIoopNipKFLJL2dlF048/9g+7RiAYURS9LywMr0bUv/Vy6iZrVvSUsCn2gTz8dLxBOSnuuAcmr5dszeEA+tOY7TgdWAycDLVRhA8Q6oSW/WJsXSElMj2lBLPEcCHwLupG9bKtYBNbB9XwD8AfhdSzzFSHo9sB+zHzRsViwo6m/bPdcBkRric8CNpArfpUwA1nQzs0Ca9GZtUiyVprShygeANWw3IZZK09r3gra/UjqIFmcDPwFOpDntGmpu273YAa1ge4vSQQC3k8odPVY6kDaa9GZtUiyVprShyn3APDSjM6w0rX3/WtJ7bV9UOpDsJds/Lh1EG7W27V7sgK6WtLbt2wrHsQRwp6TraPngKFVlvJ8mvVmbFEulKW2o8jwwWdLl9G1Lny0XUuPa977AAZJmAC9Sfj7jhZI+Q6os0/r6PF0onkqtbbvn5gFJuhN4HXA/6R9fNcR1ao5j03bbbV9VZxztSJoKLER6fYq+WZsUS0tMjWhDLfF8rN1226fWHUulye27CSTd32azba9aezAt6m7bvdgBrdxuu+3hWGMo9IBoQyOTpMWB1YH5q22lMwWbpu623XNDcNULKWkpWhpi3SRtCBwLvBGYFxgLTGtKiaMmvVmbFEvedyPaUEXS6sARwJr0fY2KHU03rX1L2pM0DLcCKTNvQ+AaoFjWmaS1mP1/VjQLtva2bbunvoCtgbtJde7uB14B7igQxw2kU92bSW/O3YEjSr8+ObY9gduAZ4DfA/8Gruj1WJrWhlri+SPwLuBWUlrvIcChhV+jRrXv3IbmBybn228AzisYz8G5Pf8DOAV4HDin5P8sx1Vr2+7FSgiHkY5+/mZ7FdIb988lArF9DzDWae2lU4CmZFbtC6wPPGj7ncBbgGcjlpka04ayBWxfThpSf9D2IaRlVIpqWPuebns6pLkutv8KrFEwnu1J7eZx27sD6wKLFoynUmvb7rkhOOBF209JGiNpjO3fS/pegTielzQvKXvpKFK6alMOCKbbni5p5ptVUqk3a5NiqTSlDVVmSBoD3J0XjHwEWLhgPNC89v2wpMWA84HLJD0DlLxm92/br0h6SdI44AlgxYLxVGpt273YAT0raWHS5MYzJT3BrGUn6vQR0htyH+DzpMa3XYE42mnSm7VJsVSa0oYq+wILAp8lHcG+E2ibGVejRrVv2x/MPx4i6feks41LSsUD3JDb9YmkSZ//Il2TKq3Wtt2LWXALka4jjAF2ITXEM20/VSCWBYCVbN9V9747ldNpFwUusf1CxNKsNtQvrgVtP18yhlZNa9+SNgFWt31KLvG0sO126dB1xzUeGGf71gbEUmvbbsqQT21sTyMdjU10midxElD7h5mk95OycS7Jt98saVLdcQxE0iaSdneat3ENsHzEkjSlDVUkbZTnb/w1315X0o9KxZNjaFT7lnQw8BVg/7xpHuCMgvFI0q6SDrL9AOnM422l4qnU3bZ7rgOS9AngHOD4vGl50vBO3Q4B3ka+oG57MrBKgThm06Q3a5NiqTSoDVW+B7wHeArA9i3AfxaMB5rXvj9IyvCaluN5FFikYDw/AjYCdsq3pwI/LBdOUnfb7rkOCNgb2BiYAmD7bmCpAnG8aPu5ftuaMh7apDdrk2KpNKUNzWT7oX6bShe4bFr7fsHpeoNh5lBTSRvY3huYDmD7GdJ8qdJqbdu92AHNaL1+IOk1lHlj3CFpZ2CspNUlHQtcXSCOdpr0Zm1SLJWmtKHKQ0pr71jSPJK+BPylYDzQvPb9S0nHA4vlo/zfkRIASnlR0lhmteslSXNuSqu1bfdiB3SVpAOABSRtTiqLfmGBOP4beBOp3tLPSUccnysQRztNerM2KZZKU9pQ5VOkI9flSSnYb863S2pU+7b9HdLQ0rmk+T8H2T62VDzAD0iFSJeS9E3SZOLDC8ZTqbVt92IW3BhgD+C/SIX2LgVOcq+9EEPIjW/ma2T7sohlZjzRhkaoPOemdaG1YtWnJb2BNNFTwOW2S5+11t62e64DagpJE4ADmH3lwSIVldtp2Ju1MbE0jaRVSGcc4+n7GhVb2qNp7VvSJ4Gvk665vMKsKs8l6+UtTso4a319bioVTwk91wFJeh9psl61FG6R8v6S7iItyXsbLWO/bkBF5Sa9WZsUS0tMjWhDLfHcApzM7G2p2NIHTWvfku4GNrL9ZIn99yfpMGA34F5mXWOxyy/JXWvb7sUO6B5gW+C2kkMmkv5oe5NS+x9Mk96sTYql0pQ21BLPtbY3KB1Hq6a1b0mXANs2ZaJu7qDXLj25u7+623YvluJ5CLi9AR8cB0s6Cei/iuV55UKa6V7SKptN0KRYKk1pQ5Xv5/lSv6VvWyo5nNO09r0/abXPa2nGqrG3A4uRasA1Sa1tuxc7oC8DF0m6ir4N8bs1x7E7qST8PMwaojDQhA6oSW/WJsVSaUobqqxNqr22GX3bUsnhnKa17+OBK+g3JFjQEcDNkm6nGUuWV2pt273YAX2TVPhvfspO/FrfdumqzgNp0pu1SbFUmtKGKjsAqzZsOKdp7Xse218oHUSLU4EjaVa7hprbdi92QMvZXqt0EKSj+jVt31k6kDaa9GZtUiyVprShShOHc5rWvi+WtBdpTkvrkX2pbMrnbf+g0L4HU2vb7sUkhKOA39n+beE4/gKsRlp1cAazsk2Kp2FLOhx4gAa8WZsUS0tMjWhDFUlXAusA19OQ4ZymtW9J7apeF8umlPRd0usyieZct6u9bfdiBzQVWIj0T3+RcmnYK7fb7llrsi+e60PVrklv1ibFUmlKG2qJZ9N22wunYTe2fbcjafM6JzgrrUnUXxPSsGtt2z3XAQ1F0pts39GAOG6yvV7pONqp+806mCbFUmlKG6pIusb2RqXjaNW09t3AeD7mtBxCowx32+7FWnBDOb10AJlKBzCII0sH0KJJsVSa0oYq85cOoI2mte+mxbNv6QAGMKxtOzqg2TWlITb51LQprxE0K5ZK02JqYltqWkxNi6dpbagyrHFFBzS7pjXEJmrSa9SkWCpNjCmMLE1tQ8MaV3RAzdXUI6Aw8jSxLTUtpgdKB9BP016frogOaHa1TeaTtImk3fPPS+aqxpV31RVHv5jG5MXNBvNAHbF06IHSAbRR64RQSQvlMvpIer2krSXN0/KQj9QZT47jaElvGuQhtbZvSTtIWiT/fKCk8yTNTDqwvW3N8Ywd4iF/qiWQOTesbbvnsuAkbQxMtj1N0q7AesD3667Sm2t3TQDWsP16ScsBZ9veuM442pF0s+23lI6jImktYE1aLqbbPq1gPI1oQy3x3Ai8A1ic9MF1PWkl2V1KxJNj2pNUjuc1wCnAzz37Et11xnOr7XUkbQJ8A/g2aVG6IkVcJd1HWhzvlAZN1gVA0vLMqoYNgO3/68a+evEM6MfA85LWBb5IKnZZ4sPsg8DWwDQA248CixSIo53LJW0nqfgwQO6oj81f7wSOIr1uJTWlDVWUqzxvC/zI9g6k1UiLsX1SPpj6KGlNoFsl/UzSOwuF9HL+vhVwgu3fULaM0rrA34CTJP1Z0l55zauiJB1JOog5kLScxn7Al7q1v17sgF7KlV63AY6z/UPKfPC/kOOo1oRfqEAMA/kkaSneFyRNkTRV0pRCsWxPGq553PbupDfuooViqTSlDVUkaSNgF+A3edtQQzxdl4eZ3pC/ngRuAb4g6RcFwnlEaWn3D5GKbc5Hwc8/21Ntn2j77cBXgIOBxySdKul1peICPkAalXmv7ffnr64d8PViLbipkvYHdgX+M4+dzzPE73TDL/MbYjFJnwA+DpxYII7Z2G7KmRjAv22/IumlfIT4BGkVyZKa0oYqnyNVDf+V7TskrQq0m2lfG0nHAO8jFZI93PZ1+a4j81o4ddsR2AL4ju1nJS1LOrovInfOW5GGKccDRwNnkoZSLwJeXyi0+0htecZQDxwOvdgBfQjYGdjD9uOSViKNB9cmD22dRToynAKsQRqPbsSM/hzfLsAqtg+TtCKwbMuHSJ1ukLQYqXO+kVSp95oCcbQq3oZa5ZI7V0FKIgGeLLxcBcCtwIG2p7W57211BwMcb3tmMobtx3Lds1L1/O4mHSR82/bVLdvPkfSfhWKCtPbWZEn913HqSnvquSSEppB0m+21S8fRjqQfk0rEb2b7jUpr1//W9vqF4xoPjLN9a+E4FgKm235Z0utJBxIX236xUDw/Az5Fus5xPTCOlBRRrFOUdLntdw21rcZ4+pTayWcgt9les0AsY4Gv2T607n0PRdLH2m3vVlmgnrsGVF3PyF/TJb0sqUR2zk2Sin6gD2ID23sD0wFy0cgiF2yV7CrpINsPAM9KKnEE3er/gPlyttBvSWnO/1swnjVtTyGN318MrEKB1GsASfNLei2whKTFJb02f40Hli8Qz/5KBTbXaXnfTyUN5V5QdzwAtl8mDU82Tu5ofk4abbgR+Fk3a9L13BBc6/WNPNS0DbBhgVA2AHaR9CApE64xyzEAL+ajtCpBYknKLZr1o7zvzYBDgamk9NWSnbdsPy9pD1LW2VGSbikYzzx53s8HSEkRL0oqNbTxSdI1qeWA1qUFpgDH1R2M7SOAIyQdYXv/uvc/iD9JOo40FD9zmLIByzFMJC2W9wDpM2lFpcKoXUnDjiE4ysx70RDl6kuStAvpOsd6pMa4PfA/tn9ZIJabbK/X+j+SdIvtdeuOpSWmm4HPAMeQrgPdUXJIVdJnSZlUt5AubK8EnGH7HSXiyTH9t+1jS+2/nTrnt3QQS1OXY7gR2Nn2Xfn260lzuN7ajf313BmQpNYZz2NIk0GnFwilsT2/7TNzQ3wX6SjoA7b/UiicJp2NVT5Hg7LOnFbWbF1d88FS820kbWb7ClLa82zVBWyfVyAsJH0L+DBwJ7PmBJk0nFrCHrbva92Q21Fp81SdD4Dtv6lvVY1h1XNnQJJOabn5EulU80TbtS5nLOk20htApBn+qwB32S46gRBA0umtGUMDbasplnZnYwfaPrvuWPqTtGCeAFo6jqWBw0nLKW8paU1gI9snF4jl67YP7vc+q9j2x+uOCSCnfq9ju5b04qH0T4rI227s1plGpyT9lHSAd0betAswtlv/t57rgJpKqS7VZ2zv2YBYGpExlFOKNwSeZtbZ2OUFz8aquDYCTgYWtr2SUkWET9r+TKF4LiaVu/ma7XUlvQa4uWSWpaSx+WJ7I+TXaAfb/yocxxtIVSqOou88pHHAfqUPQJUm6O4NbJI3/YF0nbMrHXfPDMFJ+nK+WHwsbYa/Ss+bsH2TpCJ1qSp5cuUBwAJKlQ+qUjwvACfUHU+egPrDfO3nr3XvfxDfA94DTAKwfUvhuRtL2P5l/v9h+yVJpT/875d0Ceki+xUuf6Rb6/yWQaxByoBbDHh/y/apwCdqjmU2uaP5bv7qup7pgIDqqPmGolFkkr7QcnMMaYjp0ULhAI3NGLpc0nbAeQ34EJvJ9kPqWyqv5Af+NEn/wazrZBsCxQp/Zm8gfdDuDZws6dfAL2z/sVA8k/JXUbYvAC6QtJHt0hOqZ5L0S9s7tlwa6KNb2bkxBFeIUpHNSnUt6lzbJRIi+shDXzvTgEoIec7GQqTXaDqz0tWLFW6UdA7pCPE4Ujr9vsAE2x8uFM96pGKtawG3A0sC25eesFtRmsj8fWAX28Vr1DVBzi77MbC07bUkrQNsbfsbheJZNleHqDU7t2c6IEkXMkjmmbtYcK8dSTv0v5DeblsJalglhDyxcXX6LsdwVYlYcjxLkD5Q303qEH8L7Gv7qYIxvYY0vCNSMkuRqgytJG1KSiDZgjTycJbtc2uOociR/VAkXUW6BnR8y/SC222vVSKelrgWYlb9xa5X+eilDmjT/OO2wDLMyvLYCfiH7c/XHE+7LJjZtpXQpLk3SuvK7AusAEwmJSVc7UIlXZpKaRHB8fSd41JyzaQHgJuBXwKT3L4mXB1xFDmyH4qk622v3+89Ntn2m0vE0xJXrWtL9cw1oOqIWdLRtie03HWhpNquC0naEngvsLyk1rkb40jDTE3QpLk3+5KqHvzZ9jtzFtHhhWIBZr4en2D2D/xSKcanA6uROujWOS4l1yhax6k8UFG2H8vfH8zp6tVZ/HV1T73o50lJqzHrPbY98FjBeCrtqnxM7tbOeqYDarGQpFWrSWBKy2DXuRbPo6ThiK1JtZYqU4Faz8IG8QPgV8BSkr5JnntTKJbptqdLQtJ8tv8qaY1CsVQuIKWn/o6yyQeVCaR6cE0aznhB0t6klOPWodNSnfSOpIrlV5KGKY+VtJ/tc0rEQ0rOOAF4g6RHgPtJy3uUJs1aW2qPvK1r1+16sQP6PHCl0pK4IpXm+GRdO7d9C3CLUmXgh1vvyx+sz9QVy0DcrEoIDystx3A+cJmkZ4DS5YoWtP2VwjG0up00rNyEI+jK6aTU+feQavjtwqxM1BK+BqxfnfXks9jfAUU6oHwA/O58zWWM7akl4mhjX2qs8tEz14Ba5clWb8g3/1pidnSemT2zvpqkL5LKc9ReHr6dnHiwIn2HmEoXStyUtBrqJbZfKBjHN0jXoS4qFUMrpbpibwauo+8cl2JLl1fXNiTdansdpXIuf7BdovDvbMuf5EzPW0pN1s0HVdVy5a3vsdLrONWqF8+AIGVUrUEaGlhXUokLthOBEyTtACxNOjosvcwAAJIOA3YD7mVW5pBJFamLKZn51s++wAGSZgAvUj41/JBC+x1MlTX1rKS1gMeBpQrGc4mkS0lLDUBemrtgPBcBfwZuo3xtw5ly5tuXmL1j7Mp7v+fOgPL8m4nAmqRGsCXwR9vbF4hlb9Lp7ivAh913ZcRi8tnZ2iXPMkLnJB3Zf0iw3baaY9qTtGzG2qS1khYmrfr7k4IxbUtLiRnbvyoYSyMyXvtTWlbkJ6Tr0zOvb9q+ccBfejX768EO6DZgXVKtrHVzZswZtjevOY7fkRISPksa6joZ+D/bX6ozjnYknQt8unCWUKOpWaX926X031pqjktTSVqGNHH4FeB6248XjOXzpOXlf03fYdOnS8UE9RdE7cUhuOl5ktVLksaRVkZcsUAcx9k+P//8bM48OaBAHO0cAdws6XYack2hSSQdSRrCKVraX9KnSesSrSapterBIkDRs2lJhwNH2X42314c+KLtItmU+YzsIOAKZmXBHWr7pyXiIdVX/DYpOaJ1mLv0kgwXSvoMKQu26x1jT50BSRJwEvBF0togXyQdhUy2vXuBeDYBVrd9Sp5dv4jt++uOo01cdwDH0298ukHXYIpSQ0r7S1qUNGHwCOCrLXdNbcCR9MwJli3big075f/Z26tqFUq18662XSSlP2fhvs32kyX2PxBJ7T5/bLsrHWNPnQHZtqS35aOynyhV6x3nAjWz8rWoCaRkiFOAeUnVGTauO5Y2nnda5Cy0dx8wDy1HiCXYfg54TtL3gaerVF5J4yRtYPvaguGNzfO2ZuSYFgDmKxjPU6S5dpWpeVsp95AqdDeK7VXq3F9PdUDZTZLWt3297QcKxvFB4C3ATQC2H5W0SMF4Wv1B0hGk6sGtp+FF07BL06ylPJpS2r/yY1I19cq/2myr25mkSubVwnS7kxYULOUe4FpJF5D+h9sAtypXpbddy/IDLaaR2tDvaUYbAkDSgsAXgJVs7yVpdWAN27/uxv56sQPaANhF0oOkRlCl0NZ9wfaFfEZWleKosxrDUKqhk9Y5G8XTsBugKtl0I7OX9i85lq3WKgj5GmfR97btI/N1qapm32G2Ly0Y0r35q3JB/l7qoO/8/NU0p5Da99vz7UeAs0nJEsOup64BAaghRQklfYk0H2lz0hj+x4Gf2T62zjjCnJO0r+3vD7WtxnjOI5WY+XHe9BngnbY/UCKeMHJJusH2BNVUiLjnzoDq7mgGsSSpDMgU0nWgg0jl/YuRtKvtM9R3sbyZCgxTNNXHSMsxtNqtzba6fIpUv+9A0pnY5cBehWIBZs65OZI0+VSUn6zbKJLeBxzGrFT+prw+L+TrddXIzGp08Vpnz3VADbJ5nih4WbVB0tFAyRpj1TBgU65FNYqkncgL9UlqHYIbBxTLOsvztYoshjeIo4D3F6wh2HTfIy0Nc1vDisgeDFwCrCjpTFJS1G7d2ll0QDVrmbuxapu5G38qE1Vi+3ilZRim2D6mZCwNdTWp4OcSwNEt26cCxVYflTQ/qXJxIypPZ/+IzmdQDwG3N6zzwfZlkm4iXf8VaaHFrqWK99w1oNKaPHejIuk6242oS9dUatDaMpLOJlWe3pmWytO29y0Y0/dJFbrPp2+W13mF4mnaEtjrk4bgrqLv61N8mDu/NuPpW+WjK/+36IDCbCQdQ5rnchYpUxCINOxKLiD7HWatLfMOoNjaMk2rPJ1jOqXNZpc6K1PDlsCW9FtSunz/yd5fLxFPRdJPgXWAO5gVV9f+bzEEF9p5c/5+aMu2SMOe5UAatLYMzas8TYnKIkNY0PZ1qRjKTCVXIF6uVOc3hA1d45Iw0QGF2dh+Z+kYGm5MvyG3p4AxpYIhLeuxOPA/pPlJC+efi5G0AnAssyp7/IF0PeHhgX+rq5q2BPZFkv7L9m8LxtDONZLWtH1nHTuLIbgwm3x943DSUdqWktYENrJ9cuHQGkHSt0nDFK1ry9zqZq2SWpSky4CfkVZGhbTc9C6uuep8SzyrkpbAfjtp1eH7czxFpmVImkrKOm3KmlJVXJuSDmIez7F1daJ+dEBhNpIuJs2I/prTkhWvIS1fUWT1yCZq2Noy/0FalG5j0hH+H0iVB4rVOpM02fabh9pWYzxjbb+s5i2B3SiS7iGV4ul/baorHXXJYYPQXEs4LRX+CoDtl2hZnCoAKWX+96Ty/kXT54FfkJYV2Q7YHniSlEBS0lOSdpU0Nn/tStnin/dLOoGUXvyvgnEAac0tSe9VWhq8Sf5pe5Lt+20/WH11a2dN++NDM0zLR9XVePmGwHNlQ2oOSTsC15E+7HckFbmsfUXdFsvaPix/aNyfU4uXLhgPpNJSO5KGch4jvVa7FYznDaREkb1JndFxeTmUUn5MSpe/W9K3JBVZFqKNmyX9TNJOkratvrq1sxiCC7ORtB7pAvKbSOmYSwLbu8CyFU2ktGzx5v2z4LpVL6uDeL5L6hB/mTdtT1prptjqupJOBT5n+5l8+7XAdwpPjiXHsjipbNIutscWjmVRYCfSwnQPASeSVmh+cdBf7F48tabPRwcUZpNn1u8DvIc0y/8a4Fjb04sG1hCSbmu9HpaHUW4pdY2s5YJ2NWY/hlnzt4pc2Fb7Belm21ZzTJuSEka2IFU2P8v2uQXj+Q9ScsZHgEdJS1hsAqxte2KpuOoUadihndNIRVIPz7d3JmUz7VAsoma5RNKl9M2Cu7hUMLabWLtvjKTF+50BFfu8kfQAcDPpLHE/29MG/42ux/MrUhHi00k186qU8LMk3TDwb3Ytni/bPqplzas+3KV1iqIDCu2s1W8y2u8l1TIvYCSwvZ+k7Zg1x+WEkllwUG/5lA4dTZpTcna+vQPwzYLxrGN7SsH99/dz4BLbUyQdmIe9v2H7JtsTCsRT1e2rtfOLIbgwG0lnAMfZ/nO+vQGwt+2Plo2sWSSNo+8HfpFafnWXT+lUnj9WVc+4oq7JjQPE0qiCrS1lkzYBvgF8GzjI9gYl4iklzoBCO28Frpb093x7JeAuSbdRZvXYRpH0SeDrwHTSB75IwxarFgqp1vIpncodTlPOnE8nFWx9Dy0FWwvGU01r2Ip0Bv0bSUUKowJIupBBVvW1vXVX9htnQKE/DbBqbKXU7PGmkHQ3qTJE18rUzwlJJwNHlzzDaLqmFWyV9GvSctebA+sB/yZVVS+VSblp/nFbUhXzM/LtnUhLa3y+G/uNM6Awm17vYDpwL/B86SBanEa63lJL+ZQRqmkFW3ckZeN9x/azkpYlVesuwvZVkBbF7HcN6sJuJkVEBxTCnNufNER5LX3XculKplAHTial8vYpnxL6qAq2Hsisgq0HlQrG9vPAeS23H6NscdTKQpJWtX0fgKRVmLVS8rCLIbgQ5pCk64A/Mnu9rFMLxXON7Y1K7DuMLpK2IBVtvY90Jr0ysFe3qnZHBxTCHCo9obI/ST8CFgMupAGrjzaRpMOBo2w/m28vDnzR9oFFA2sgSfORShcB/NX2jJb7Nrd92bDtKzqgEOZM/jB7gNk/8EulYTdq9dEmGqAyw0221ysV00g03K9ZXAMKYc7tlL/vT9/U1SJp2G7e6qNNNFbSfNXRvKQFgPkKxzQSaeiHdC6qYYcw574CrGt7FdK6SbeQCoAWIWkFSb+S9ET+OjevSBpmORO4XNIekvYALgOKXLMb4YZ1yCw6oBDm3IG5hMompJn+J5HK65dyCimza7n8dWHeFjLbR5JKAb0xfx1m+6iyUYW4BhTCHGqZ1HgEcJvtn5VMTGja6qNh9JJ0nu1hWx8orgGFMOcekXQ8aRb7kTlrqORowlN5xdGqOvdOlF19tHHyompHkiafilmTdWtfqqKJhlp0rsqoHM7OB+IMKIQ5JmlB0iz222zfnWexr92tuRIdxLMyaQHBjUhj9FcD/237oRLxNJGke0jLHpSs/9ZYA2RSVmJBuhBCe01efbQpJP3J9sZDPzLUKYbgQhj51qk6H0jzkSQ1ZqJsQ9wg6SzgfGKy7qAkbcXsy1Yc2o19RQcUwsjXqNVHG2ocqYDsf7VsMy312AJI+gmwIPBOUnbn9sB1XdtfDMGFMLJJ+ihwANBn9VHbp5eLKoxELctVVN8XBi62/Y5u7C/mAYUwwtk+jbSOyz/y17bR+fQVk3U79u/8/XlJy5GWsVi2WzuL0/QQRoGGrT7aRKcAPyOdHQLsmrdtXiyiZvq1pMVIS4TfRBqmPKlbO4shuBDCqBeTdTvTr17efKREhOmtFbGHUwzBhRB6wVOSdpU0Nn/tSkzWbeea6gfbM2w/17ptuMUQXAihF3ycNFn3GGZN1o0q4pmkZYDlgQVyCn9V9XocKSuuO/uNIbgQQuhtkj4G7AZMAK5nVgc0BTi1W/OlogMKIYx6uVrEvv1WRD06qkX0JWk72+fWtb+4BhRC6AXrVJ0PQJ60G9UiZvfWnAUHpI5a0je6tbPogEIIvWBMPusBolrEILZs01G/t1s7i39ACKEXHA1cI6lPtYiC8TRVrUuXRwcUQhj1bJ8m6QbSCraQqkXExN3ZVUuXV8sz7E4Xly6PJIQQQggzSdoSeFe+eZntS7u2r+iAQgghlBBJCCGEEACQtKGk6yX9S9ILkl6WNKVb+4sOKIQQQuU4YCfgbmABYE/gh93aWXRAIYQQZrJ9DzDW9su2TwG26Na+IgsuhBBC5XlJ8wKTJR0FPEYXT1TiDCiEEELlI6R+YR9gGrAisF23dhZZcCGEEJA0FjjN9i517TPOgEIIIWD7ZWDlPARXi7gGFEIIoXIf8CdJk0hDcADY/m43dhZnQCGE0OMknZ5/3Br4NalvWKTlqyviDCiEEMJbJS0H/J20cmwtogMKIYTwE+ByYBXghpbtIi1hvmo3dhpZcCGEEACQ9GPbn65tf9EBhRBCKCGSEEIIIRQRHVAIIYQiogMKIYRQRHRAIYQQivh/vbgE3+TmYJoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "forest_importances = pd.Series(importances, index=feature_names)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "forest_importances.plot.bar(yerr=std, ax=ax)\n",
    "ax.set_title(\"Feature importances using MDI\")\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can observe that some of the features (smoothness_mean, symmetry_mean, fractal_dimension_mean) are not that useful while building a Random Forest model.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f640a9078f8e092032cb0185e0c2b2c1ad2376cf3b94da3c4476fa7bf4b3609c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
