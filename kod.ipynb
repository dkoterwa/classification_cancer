{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"notebook_connected\"\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import seaborn as sns\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"df = pd.read_csv(\\\"/Users/dominik/Desktop/breast-cancer.csv\\\")\\n\",\n",
    "    \"df.head()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"df.dtypes\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"df.describe()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"**DATASET DESCRIPTION**\\n\",\n",
    "    \"\\n\",\n",
    "    \"radius_mean - the mean of the radius of the breast lobe \\\\\\n\",\n",
    "    \"texture_mean - mean of surface texture \\\\\\n\",\n",
    "    \"perimeter_mean - outer perimeter of lobes (obwód) \\\\\\n\",\n",
    "    \"area_mean - mean area of lobes \\\\\\n\",\n",
    "    \"smoothness_mean - mean of smoothness levels \\\\\\n\",\n",
    "    \"compactness_mean - mean of compactness \\\\\\n\",\n",
    "    \"concavity_mean - mean of concavity \\\\\\n\",\n",
    "    \"concave points_mean - mean of concave points (punkty wklęsłe) \\\\\\n\",\n",
    "    \"symmetry_mean - mean of symmetry \\\\\\n\",\n",
    "    \"fractal_dimension_mean - mean of fractal dimension \\n\",\n",
    "    \"\\n\",\n",
    "    \"SE means the standard error of the mean of the breast examination variables \\n\",\n",
    "    \"\\n\",\n",
    "    \"worst means the worst examination result\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"del df['id']\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"df['diagnosis'].value_counts()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"df.loc[df['diagnosis'] == 'M', 'diagnosis'] = 1\\n\",\n",
    "<<<<<<< HEAD\n",
    "    \"df.loc[df['diagnosis'] == 'B', 'diagnosis'] = 0\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"df.head()\"\n",
    "=======\n",
    "    \"df.loc[df['diagnosis'] == 'B', 'diagnosis'] = 0\\n\"\n",
    ">>>>>>> main\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"fig = px.histogram(df['radius_mean'], nbins = 60)\\n\",\n",
    "    \"fig.update_layout(bargap=0)\\n\",\n",
    "    \"fig.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"\\n\",\n",
    "    \"df_corr = df.corr()\\n\",\n",
    "    \"\\n\",\n",
    "    \"fig = go.Figure()\\n\",\n",
    "    \"fig.add_trace(\\n\",\n",
    "    \"    go.Heatmap(\\n\",\n",
    "    \"    z=np.array(df_corr),\\n\",\n",
    "    \"    x=df_corr.index ,\\n\",\n",
    "    \"    y=df_corr.columns,\\n\",\n",
    "    \"    colorscale=px.colors.diverging.RdBu,\\n\",\n",
    "    \"    zmin=-1,\\n\",\n",
    "    \"    zmax=1\\n\",\n",
    "    \"    )\\n\",\n",
    "    \")\\n\",\n",
    "    \"fig.show()\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"df.groupby('diagnosis').mean()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "<<<<<<< HEAD\n",
    "=======\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"df.iloc[:,1:]\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 14,\n",
    ">>>>>>> main\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"plot_data = df.iloc[:, 1:]\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"for col in plot_data.columns:\\n\",\n",
    "    \"\\n\",\n",
    "    \"    fig = px.histogram(\\n\",\n",
    "    \"        df,\\n\",\n",
    "    \"        x =\\\"diagnosis\\\",\\n\",\n",
    "    \"        y = col,\\n\",\n",
    "    \"        color = \\\"diagnosis\\\",\\n\",\n",
    "    \"        histfunc = \\\"avg\\\"\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"\\n\",\n",
    "    \"    fig.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"df_model = [df[col] for col in df.columns if 'mean' in col]\\n\",\n",
    "    \"df_model = pd.DataFrame(df_model).T\\n\",\n",
    "    \"df_model['diagnosis'] = df['diagnosis']\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"df_model.describe()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"y = df_model['diagnosis']\\n\",\n",
    "    \"del df_model['diagnosis']\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"    I will try to fit 3 logistic regression models:\\n\",\n",
    "    \"1. Model with all variables from df_model dataframe\\n\",\n",
    "    \"2. 2 RFE models, which builds multiple models and checks if adding an additional variables makes the model better (will select 6 and 8 features) \"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"    First model\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"y = y.astype(int)\\n\",\n",
    "    \"\\n\",\n",
    "    \"X_train, X_test, y_train, y_test = train_test_split(df_model, y, test_size = 0.3, random_state = 0)\\n\",\n",
    "    \"logreg = LogisticRegression()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"smlog = sm.Logit(y, sm.add_constant(df_model)).fit()\\n\",\n",
    "    \"smlog.summary()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"probability = 1 / (1 + np.exp(-smlog.fittedvalues))\\n\",\n",
    "    \"px.histogram(probability)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"y_train = y_train.astype(int)\\n\",\n",
    "    \"logreg = LogisticRegression()\\n\",\n",
    "    \"logreg.fit(X_train, y_train)\\n\",\n",
    "    \"y_pred = logreg.predict(X_test)\\n\",\n",
    "    \"print('Accuracy on test set: {:.2f}'.format (logreg.score(X_test, y_test)))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"confusion_matrix = confusion_matrix(y_test, y_pred)\\n\",\n",
    "    \"print(confusion_matrix)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"    Second model (RFE with 8 features)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"logreg = LogisticRegression()\\n\",\n",
    "    \"df_model2 = df_model\\n\",\n",
    "    \"y = y.astype(int)\\n\",\n",
    "    \"\\n\",\n",
    "    \"rfe = RFE(logreg, n_features_to_select=8)\\n\",\n",
    "    \"rfe = rfe.fit(df_model2, y)\\n\",\n",
    "    \"print(rfe.support_)\\n\",\n",
    "    \"print(rfe.ranking_)\\n\",\n",
    "    \"print(rfe)\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"df_model.head()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"df_model2 = df_model2.drop(['area_mean', 'fractal_dimension_mean'], axis = 1)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"smlog_2 = sm.Logit(y, sm.add_constant(df_model2))\\n\",\n",
    "    \"results = smlog_2.fit()\\n\",\n",
    "    \"print(results.summary2())\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"probability = 1 / (1 + np.exp(-results.fittedvalues))\\n\",\n",
    "    \"px.histogram(probability)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"X_train, X_test, y_train, y_test = train_test_split(df_model2, y, test_size=0.3, random_state=0)\\n\",\n",
    "    \"logreg = LogisticRegression()\\n\",\n",
    "    \"logreg.fit(X_train, y_train)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"y_pred = logreg.predict(X_test)\\n\",\n",
    "    \"print('Accuracy on test set: {:.2f}'.format (logreg.score(X_test, y_test)))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"confusion_matrix = confusion_matrix(y_test, y_pred)\\n\",\n",
    "    \"print(confusion_matrix)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(classification_report(y_test, y_pred))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"    Third model (RFE with 5 features)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"rfe = RFE(logreg, n_features_to_select=5)\\n\",\n",
    "    \"rfe = rfe.fit(df_model, y)\\n\",\n",
    "    \"print(rfe.support_)\\n\",\n",
    "    \"print(rfe.ranking_)\\n\",\n",
    "    \"print(rfe)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"df_model.head()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"df_model3 = df_model.drop(['texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean', 'fractal_dimension_mean'], axis = 1)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"smlog_3 = sm.Logit(y, sm.add_constant(df_model3))\\n\",\n",
    "    \"results = smlog_3.fit()\\n\",\n",
    "    \"print(results.summary2())\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"probability = 1 / (1 + np.exp(-results.fittedvalues))\\n\",\n",
    "    \"px.histogram(probability)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"X_train, X_test, y_train, y_test = train_test_split(df_model3, y, test_size=0.3, random_state=0)\\n\",\n",
    "    \"logreg.fit(X_train, y_train)\\n\",\n",
    "    \"y_pred = logreg.predict(X_test)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print ('Accuracy on the test test {:.2f}'.format (logreg.score(X_test, y_test)))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"confusion_matrix = confusion_matrix(y_test, y_pred)\\n\",\n",
    "    \"print(confusion_matrix)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(classification_report(y_test, y_pred))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"X_test['predicted'] = y_pred.reshape(-1,1)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"X_test.groupby('predicted').mean()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"    Let's try to fit the data with another algorithm - SVM\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"from sklearn.preprocessing import scale\\n\",\n",
    "    \"from sklearn.metrics import plot_confusion_matrix\\n\",\n",
    "    \"\\n\",\n",
    "    \"y = y.astype(int)\\n\",\n",
    "    \"X_train, X_test, y_train, y_test = train_test_split(df_model, y, test_size = 0.3, random_state = 0)\\n\",\n",
    "    \"\\n\",\n",
    "    \"X_train_scaled = scale(X_train)\\n\",\n",
    "    \"X_test_scaled = scale(X_test)\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"from sklearn.svm import SVC\\n\",\n",
    "    \"svm = SVC()\\n\",\n",
    "    \"svm.fit(X_train_scaled, y_train)\\n\",\n",
    "    \"\\n\",\n",
    "    \"y_pred = svm.predict(X_test_scaled)\\n\",\n",
    "    \"plot_confusion_matrix(svm, X_test_scaled, y_test)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(classification_report(y_test, y_pred))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"    As we can see, SVM perform better. It is more often chosen when it comes to handling little observations. Let's find out if we can somehow optimize the parameters by executing Cross Validation (GridSearchCV)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"from numpy import linspace\\n\",\n",
    "    \"\\n\",\n",
    "    \"initial_gamma = ['scale']\\n\",\n",
    "    \"additional_gammas = np.arange(0, 1, 0.01)\\n\",\n",
    "    \"additional_gammas = additional_gammas.tolist()\\n\",\n",
    "    \"gammas = initial_gamma + additional_gammas\\n\",\n",
    "    \"\\n\",\n",
    "    \"param_grid = [\\n\",\n",
    "    \"    {'C': np.arange(1, 100, 1),\\n\",\n",
    "    \"    'gamma': gammas,\\n\",\n",
    "    \"    'kernel': ['rbf']}\\n\",\n",
    "    \"]\\n\",\n",
    "    \"\\n\",\n",
    "    \"optimal_params = GridSearchCV(\\n\",\n",
    "    \"    SVC(),\\n\",\n",
    "    \"    param_grid,\\n\",\n",
    "    \"    cv = 5,\\n\",\n",
    "    \"    scoring = 'accuracy',\\n\",\n",
    "    \"    verbose = 2\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"optimal_params.fit(X_train_scaled, y_train)\\n\",\n",
    "    \"print(optimal_params.best_params_)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"    It seems like C = 81, gamma = 0.02 are the optimal values of parameters, let's fit a final SVM model\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"reg_svm = SVC(C = 81, gamma = 0.02)\\n\",\n",
    "    \"reg_svm.fit(X_train_scaled, y_train)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plot_confusion_matrix(reg_svm, X_test_scaled, y_test)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"y_pred = reg_svm.predict(X_test_scaled)\\n\",\n",
    "    \"print(classification_report(y_test, y_pred))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"    We were able to achieve better performance of the model with a regularization\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"    Now let's start with non-linear classification models (KNN, Decision Tree Classification, Random Forest)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"from sklearn import neighbors\\n\",\n",
    "    \"from sklearn.neighbors import KNeighborsClassifier\\n\",\n",
    "    \"n_neighbors = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\\n\",\n",
    "    \"\\n\",\n",
    "    \"for neighbor in n_neighbors:\\n\",\n",
    "    \"    knn = KNeighborsClassifier(n_neighbors = neighbor)\\n\",\n",
    "    \"    knn.fit(X_train_scaled, y_train)\\n\",\n",
    "    \"    y_pred = knn.predict(X_test_scaled)\\n\",\n",
    "    \"    print('For the number of neighbors {:.2f}'.format(neighbor) + ' accuracy = {:.2f}'.format(knn.score(X_test_scaled, y_test)))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"    The smallest number of neighbors giving the best predictions is 6, let's take a closer look at this configuration\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"knn = KNeighborsClassifier(n_neighbors = 6)\\n\",\n",
    "    \"knn.fit(X_train_scaled, y_train)\\n\",\n",
    "    \"y_pred = knn.predict(X_test_scaled)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plot_confusion_matrix(knn, X_test_scaled, y_test)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(classification_report(y_test, y_pred))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"    Once again we've found a better performance than logistic regression, however, a little bit worse than SVM. Let's try to visualize the Test Set results\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"df_visualize = X_test_scaled.copy()\\n\",\n",
    "    \"df_visualize = pd.DataFrame(df_visualize)\\n\",\n",
    "    \"df_visualize.columns = X_test.columns\\n\",\n",
    "    \"df_visualize ['prediction'] = y_pred\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"sns.relplot(x = 'radius_mean', y = 'texture_mean', hue = 'prediction', data = df_visualize)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"As we can see - larger mean of the tumor radius and texture leads to the positive prediction of the cancer \\\\\\n\",\n",
    "    \"    Let's find out how the decision surface looks like for these two characteristics for differenct configurations of the number of neighbors\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"def knn_comparison(data, k):\\n\",\n",
    "    \" x = data[['radius_mean','texture_mean']].values\\n\",\n",
    "    \" y = data['prediction'].astype(int).values\\n\",\n",
    "    \" clf = neighbors.KNeighborsClassifier(n_neighbors=k)\\n\",\n",
    "    \" clf.fit(x, y)\\n\",\n",
    "    \"# Plotting decision region\\n\",\n",
    "    \" plot_decision_regions(x, y, clf=clf, legend=2)\\n\",\n",
    "    \"# Adding axes annotations\\n\",\n",
    "    \" plt.xlabel('radius_mean')\\n\",\n",
    "    \" plt.ylabel('texture_mean')\\n\",\n",
    "    \" plt.title('Knn with K='+ str(k))\\n\",\n",
    "    \" plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"for i in [1, 5, 6, 20, 30, 40, 80]:\\n\",\n",
    "    \"    knn_comparison(df_visualize, i)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"    Let's try to fit the first decision tree to our training data\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"clf_dt = DecisionTreeClassifier()\\n\",\n",
    "    \"clf_dt = clf_dt.fit(X_train, y_train)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"Let's see how our first tree looks like\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"from sklearn import tree\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"fig = plt.figure(figsize = (150,120))\\n\",\n",
    "    \"_ = tree.plot_tree(clf_dt, feature_names = X_train.columns, class_names = [\\\"No cancer\\\", \\\"Cancer\\\"], filled = True)\\n\",\n",
    "    \"fig.savefig(\\\"/Users/dominik/Desktop/binary_tree.png\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"plot_confusion_matrix(clf_dt, X_test, y_test)\\n\",\n",
    "    \"y_pred = clf_dt.predict(X_test)\\n\",\n",
    "    \"print(classification_report(y_test, y_pred))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"We can clearly see that our classification tree overfits the data. Moreover, the tree is really huge and maybe we can make it smaller. Let's try to execute data pruning\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"path = clf_dt.cost_complexity_pruning_path(X_train, y_train)\\n\",\n",
    "    \"ccp_alphas = path.ccp_alphas\\n\",\n",
    "    \"ccp_alphas = ccp_alphas[:-1]\\n\",\n",
    "    \"\\n\",\n",
    "    \"clf_dts = []\\n\",\n",
    "    \"\\n\",\n",
    "    \"for ccp_alpha in ccp_alphas:\\n\",\n",
    "    \"    clf_dt = DecisionTreeClassifier(ccp_alpha = ccp_alpha)\\n\",\n",
    "    \"    clf_dt.fit(X_train, y_train)\\n\",\n",
    "    \"    clf_dts.append(clf_dt)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"train_scores = [clf_dt.score(X_train, y_train) for clf_dt in clf_dts]\\n\",\n",
    "    \"test_scores = [clf_dt.score(X_test, y_test) for clf_dt in clf_dts]\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"fig, ax = plt.subplots()\\n\",\n",
    "    \"ax.set_xlabel('alpha')\\n\",\n",
    "    \"ax.set_ylabel('accuracy')\\n\",\n",
    "    \"ax.set_title('Accuracy depending on the alpha parameter: training vs. testing')\\n\",\n",
    "    \"ax.plot(ccp_alphas, train_scores, marker = 'o', label = 'train', drawstyle = 'steps-post')\\n\",\n",
    "    \"ax.plot(ccp_alphas, test_scores, marker = 'o', label = 'test', drawstyle = 'steps-post')\\n\",\n",
    "    \"ax.legend()\\n\",\n",
    "    \"plt.show\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"we can see that we don't lose any testing accuracy between alpha = 0 and alpha = 0.005, let's choose the \\\"marginal\\\" value to make the tree simpler and limit the overfitting problem. Additionally, we will do some crossvalidation.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"from sklearn.model_selection import cross_val_score\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"clf_dt = DecisionTreeClassifier(ccp_alpha = 0.00489138)\\n\",\n",
    "    \"scores = cross_val_score(clf_dt, X_train, y_train, cv = 5)\\n\",\n",
    "    \"df = pd.DataFrame(data = {'tree' : range(5), 'accuracy' : scores})\\n\",\n",
    "    \"\\n\",\n",
    "    \"df.plot(x = 'tree', y = 'accuracy', marker = 'o')\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"we may assume that our \\\"best\\\" tree performed this good only on one specific type of the training data, a good idea is to perform cross validation with every value of alpha and check which configuration has the largest mean of the accuracy\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"\\n\",\n",
    "    \"statistics = []\\n\",\n",
    "    \"for ccp_alpha in ccp_alphas:\\n\",\n",
    "    \"    clf_dt = DecisionTreeClassifier(ccp_alpha = ccp_alpha)\\n\",\n",
    "    \"    clf_dt.fit(X_train, y_train)\\n\",\n",
    "    \"    scores = cross_val_score(clf_dt, X_train, y_train, cv = 10)\\n\",\n",
    "    \"    statistics.append([ccp_alpha, np.mean(scores), np.std(scores)])\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"statistics\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"cv_results = pd.DataFrame(statistics, columns = ['alpha_value', 'mean_accuracy', 'standard_deviation'])\\n\",\n",
    "    \"cv_results.plot(x = 'alpha_value', y = 'mean_accuracy', yerr = 'standard_deviation', marker = 'o')\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"Now we can see that the optimal value for alpha is less than the previus one which was used. Let's see our final model.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"clf_dt = DecisionTreeClassifier(ccp_alpha = 0.00326737)\\n\",\n",
    "    \"clf_dt.fit(X_train, y_train)\\n\",\n",
    "    \"plot_confusion_matrix(clf_dt, X_test, y_test)\\n\",\n",
    "    \"\\n\",\n",
    "    \"y_pred = clf_dt.predict(X_test)\\n\",\n",
    "    \"print(classification_report(y_test, y_pred))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"fig = plt.figure(figsize = (100,80))\\n\",\n",
    "    \"_ = tree.plot_tree(clf_dt, feature_names = X_train.columns, class_names = [\\\"No cancer\\\", \\\"Cancer\\\"], filled = True)\\n\",\n",
    "    \"fig.savefig(\\\"/Users/dominik/Desktop/binary_tree_final.png\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"By performing cross validation and tree pruning we were able to achieve higher and construct a simper tree.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"    Let's check the performance of the last model - Random Forest\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"df_model.head()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"from sklearn.ensemble import RandomForestClassifier\\n\",\n",
    "    \"\\n\",\n",
    "    \"#we will check what is the optimal number of trees\\n\",\n",
    "    \"num_trees = [20, 40, 60, 80, 100, 120, 140]\\n\",\n",
    "    \"configurations = []\\n\",\n",
    "    \"for trees in num_trees:\\n\",\n",
    "    \"    performance_train = []\\n\",\n",
    "    \"    performance_test = []\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    for i in range(10):\\n\",\n",
    "    \"        model = RandomForestClassifier(n_estimators = trees, oob_score=True)\\n\",\n",
    "    \"        model.fit(df_model, y)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"        score_train = model.score(df_model, y)\\n\",\n",
    "    \"        score_test = model.oob_score_\\n\",\n",
    "    \"        performance_train.append(score_train)\\n\",\n",
    "    \"        performance_test.append(score_test)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    configurations.append([trees, np.mean(performance_train), np.mean(performance_test)])\\n\",\n",
    "    \"    print(\\\"For the number of trees: {}, traininig accuracy = {}, testing accuracy= {}\\\".format(trees, np.mean(performance_train), np.mean(performance_test)))\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"It seems like the number of trees = 100 is an optimal value. Let's fit a final model and check the importance of the features\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"feature_names = df_model.columns\\n\",\n",
    "    \"\\n\",\n",
    "    \"forest = RandomForestClassifier()\\n\",\n",
    "    \"forest.fit(df_model, y)\\n\",\n",
    "    \"\\n\",\n",
    "    \"importances = forest.feature_importances_\\n\",\n",
    "    \"std = np.std([tree.feature_importances_ for tree in forest.estimators_], axis = 0)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"forest_importances = pd.Series(importances, index=feature_names)\\n\",\n",
    "    \"\\n\",\n",
    "    \"fig, ax = plt.subplots()\\n\",\n",
    "    \"forest_importances.plot.bar(yerr=std, ax=ax)\\n\",\n",
    "    \"ax.set_title(\\\"Feature importances using MDI\\\")\\n\",\n",
    "    \"ax.set_ylabel(\\\"Mean decrease in impurity\\\")\\n\",\n",
    "    \"fig.tight_layout()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"We can observe that some of the features (smoothness_mean, symmetry_mean, fractal_dimension_mean) are not that useful while building a Random Forest model.\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3.8.8 ('base')\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.8.8\"\n",
    "  },\n",
    "  \"orig_nbformat\": 4,\n",
    "  \"vscode\": {\n",
    "   \"interpreter\": {\n",
    "    \"hash\": \"f640a9078f8e092032cb0185e0c2b2c1ad2376cf3b94da3c4476fa7bf4b3609c\"\n",
    "   }\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 2\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f640a9078f8e092032cb0185e0c2b2c1ad2376cf3b94da3c4476fa7bf4b3609c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
